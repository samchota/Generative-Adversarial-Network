{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "# From a PR that is not pulled into Keras\n",
    "# https://github.com/fchollet/keras/pull/3677\n",
    "# I updated the code to work on Keras 2.x\n",
    "\n",
    "class MinibatchDiscrimination(Layer):\n",
    "    \"\"\"Concatenates to each sample information about how different the input\n",
    "    features for that sample are from features of other samples in the same\n",
    "    minibatch, as described in Salimans et. al. (2016). Useful for preventing\n",
    "    GANs from collapsing to a single output. When using this layer, generated\n",
    "    samples and reference samples should be in separate batches.\n",
    "    # Example\n",
    "    ```python\n",
    "        # apply a convolution 1d of length 3 to a sequence with 10 timesteps,\n",
    "        # with 64 output filters\n",
    "        model = Sequential()\n",
    "        model.add(Convolution1D(64, 3, border_mode='same', input_shape=(10, 32)))\n",
    "        # now model.output_shape == (None, 10, 64)\n",
    "        # flatten the output so it can be fed into a minibatch discrimination layer\n",
    "        model.add(Flatten())\n",
    "        # now model.output_shape == (None, 640)\n",
    "        # add the minibatch discrimination layer\n",
    "        model.add(MinibatchDiscrimination(5, 3))\n",
    "        # now model.output_shape = (None, 645)\n",
    "    ```\n",
    "    # Arguments\n",
    "        nb_kernels: Number of discrimination kernels to use\n",
    "            (dimensionality concatenated to output).\n",
    "        kernel_dim: The dimensionality of the space where closeness of samples\n",
    "            is calculated.\n",
    "        init: name of initialization function for the weights of the layer\n",
    "            (see [initializations](../initializations.md)),\n",
    "            or alternatively, Theano function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "        weights: list of numpy arrays to set as initial weights.\n",
    "        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n",
    "            (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n",
    "            applied to the network output.\n",
    "        W_constraint: instance of the [constraints](../constraints.md) module\n",
    "            (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "        input_dim: Number of channels/dimensions in the input.\n",
    "            Either this argument or the keyword argument `input_shape`must be\n",
    "            provided when using this layer as the first layer in a model.\n",
    "    # Input shape\n",
    "        2D tensor with shape: `(samples, input_dim)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, input_dim + nb_kernels)`.\n",
    "    # References\n",
    "        - [Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nb_kernels, kernel_dim, init='glorot_uniform', weights=None,\n",
    "                 W_regularizer=None, activity_regularizer=None,\n",
    "                 W_constraint=None, input_dim=None, **kwargs):\n",
    "        self.init = initializers.get(init)\n",
    "        self.nb_kernels = nb_kernels\n",
    "        self.kernel_dim = kernel_dim\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = [InputSpec(ndim=2)]\n",
    "\n",
    "        if self.input_dim:\n",
    "            kwargs['input_shape'] = (self.input_dim,)\n",
    "        super(MinibatchDiscrimination, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = [InputSpec(dtype=K.floatx(),\n",
    "                                     shape=(None, input_dim))]\n",
    "\n",
    "        self.W = self.add_weight(shape=(self.nb_kernels, input_dim, self.kernel_dim),\n",
    "            initializer=self.init,\n",
    "            name='kernel',\n",
    "            regularizer=self.W_regularizer,\n",
    "            trainable=True,\n",
    "            constraint=self.W_constraint)\n",
    "\n",
    "        # Set built to true.\n",
    "        super(MinibatchDiscrimination, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        activation = K.reshape(K.dot(x, self.W), (-1, self.nb_kernels, self.kernel_dim))\n",
    "        diffs = K.expand_dims(activation, 3) - K.expand_dims(K.permute_dimensions(activation, [1, 2, 0]), 0)\n",
    "        abs_diffs = K.sum(K.abs(diffs), axis=2)\n",
    "        minibatch_features = K.sum(K.exp(-abs_diffs), axis=2)\n",
    "        return K.concatenate([x, minibatch_features], 1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], input_shape[1]+self.nb_kernels\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'nb_kernels': self.nb_kernels,\n",
    "                  'kernel_dim': self.kernel_dim,\n",
    "                  'init': self.init.__name__,\n",
    "                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n",
    "                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n",
    "                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n",
    "                  'input_dim': self.input_dim}\n",
    "        base_config = super(MinibatchDiscrimination, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
